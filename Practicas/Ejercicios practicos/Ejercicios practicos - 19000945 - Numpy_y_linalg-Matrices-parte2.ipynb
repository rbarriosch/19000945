{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios prácticos - 19000945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Ejemplo en DS** : en inteligencia artificial y ML en la sub-rama \"reinforcement learning\" la \"ecuacion de bellman\" puede aplicarse de manera vectorizada a traves del operar vectores, matrices y escalares en una sola expresion.\n",
    "\n",
    "<img src=\"https://rebornhugo.github.io/assets/images/post_images/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A02/bellman%20equation2.PNG\">\n",
    "\n",
    "* n = numero de estados del sistema.\n",
    "* V(s) = vector que representa el valor esperado para cierto estado\n",
    "* R = recompensa inmediata percibida por el agente al salir de cierto estado.(vector)\n",
    "* P = matriz de transicion de la cadena de Markov sub-yacente.(matriz)\n",
    "* γ = factor de descuento de recompensas futuras(escalar)\n",
    "\n",
    "Calcular V(s) para el siguiente sistema aplicando la ecuación de bellman de manera vectorizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.  2.  5.]\n"
     ]
    }
   ],
   "source": [
    "V = np.array([0,0,0]) # valor inicial de V(s)\n",
    "R = np.array([10,2,5]) # vector de recompensas\n",
    "P = np.array([[0.5,0.25,0.25],\n",
    "              [0.2,0.40,0.40],\n",
    "              [0.80,0.10,0.10]])  # matriz de transición\n",
    "gamma = 0.99\n",
    "\n",
    "# Calculamos V(s)\n",
    "VS = R + (gamma*np.matmul(P,V))\n",
    "\n",
    "print(VS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio \n",
    "\n",
    "Implementar en una funcion neural_network(X) la red neuronal definida por la siguiente arquitectura:\n",
    "\n",
    "<img src=\"http://i.imgur.com/UNlffE1.png\">\n",
    "\n",
    "Podemos validar si fue correctamente implementada si usamos como entrada el vector x=[1,1] . Debemos obtener el resultado mostrado en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69269553]]\n"
     ]
    }
   ],
   "source": [
    "# Declaracion de funcion de activacion\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Implementacion de la funcion neural_network(x)\n",
    "def neural_network(x, funcion_activacion):\n",
    "    H1_W = np.array([[0.712,0.355,0.268],\n",
    "                     [0.112,0.855,0.468]])\n",
    "    \n",
    "    OL_W = np.array([[0.116],\n",
    "                     [0.329],\n",
    "                     [0.708]])\n",
    "\n",
    "    H1 = np.matmul(x,H1_W)\n",
    "    H1 = funcion_activacion(H1)  # Aplicar funcion de activacion\n",
    "    OL = np.matmul(H1,OL_W)\n",
    "    OL = funcion_activacion(OL)  # Aplicar funcion de activacion\n",
    "    \n",
    "    return OL\n",
    "\n",
    "# Llamada a la funcion con el vector de entrada X\n",
    "X =  np.array([[1,1]])\n",
    "\n",
    "print(neural_network(X, sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Una vez tenemos la implementacion correcta, cambiar la funcion de activacion de la capa de salida por la funcion de activacion ReLu(https://en.wikipedia.org/wiki/Rectifier_(neural_networks)):\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*DfMRHwxY1gyyDmrIAd-gjQ.png\">\n",
    "\n",
    "Luego evaluar la red neuronal sobre la matriz de datos X(de manera vectorizada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2901751]\n",
      "[0.39827325]\n",
      "[7.576334]\n",
      "[8.423358]\n",
      "[5.852072]\n",
      "[0.6172441]\n",
      "[7.797727]\n",
      "[164.0393]\n",
      "[7.728965]\n",
      "[1055.1858]\n"
     ]
    }
   ],
   "source": [
    "# Definir funcion de activacion ReLu\n",
    "def ReLu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "# Llamada a la funcion con el vector de entrada X\n",
    "X = np.array([\n",
    "    [0.1,2],\n",
    "    [0.3,0.45],\n",
    "    [5,9],\n",
    "    [12,6],\n",
    "    [7,5],\n",
    "    [0.3,0.8],\n",
    "    [12,5],\n",
    "    [100,200],\n",
    "    [7,8],\n",
    "    [300,1500]])\n",
    "\n",
    "# Iterar los elementos del vector de entrada\n",
    "for i in X:\n",
    "    print(neural_network(i, ReLu))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
